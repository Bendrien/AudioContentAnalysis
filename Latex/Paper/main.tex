% Template for ICASSP-2016 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{blindtext}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{AUTOMATED TRANSCRIPTION OF DRUMSOUNDS}
%
% Single address.
% ---------------
\name{Anyere Bendrien, Maximilian Wagenbach
    \thanks{Thanks to Holger Kirchhof and Tim Flohrer for assistance. Also thanks to TELECOM ParisTech - Dep. TSIe for generously providing the ENST drum test data set.}}
\address{Technical University of Berlin\\
    Audiocommunication Group\\
    Einsteinufer 17, 10587 Berlin}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Using math to do magic is easy.
While it is very easy for us humans to find patterns and percussive events in music such a task is very difficult for a computer.
In this research we showed that it is possible for a computer to find the exact time points of drum events in a piece of music by using non-negative matrix factorization.
Generating such a so called drum transcription can have lots of different applications.
By using relatively straightforward math and well established techniques that others before us have researched we hoped to get a reliable drum transcription algorithm.
In doing so we were able to get detection rates of up to 90\%.

%Stark verkürzte, überblicksartige Darstellung von Forschungsbedarf, Fragestellung, Methode, erwartetem Ergebnis und Nutzen.
%The abstract should contain about 100 to 150 words.
\end{abstract}
%
\begin{keywords}
Drum Transcription, Non-Negative Matrix Factorization, Onset Detection%, Profit
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

For this research paper we looked into the topic of generating a drum transcription from a piece of music containing a recording of a drum kit.
Drum transcription is considered a classical music information retrieval (MIR) problem, where you want to extract information from a mixed piece of music.
In order to achieve this an algorithm is applied to the raw sound data to find the time points where a drum event happens in the song.
This list of time points and a corresponding flag with the kind of the drum event is called the drum transcription. 
While in theory this can be used to find any kind of event within a musical piece, we focused mainly on basic drum sounds in our research.

The transcription of the drum track of a song can be useful in many cases.
The simplest would be to generate the sheet music for a song where the original has been lost or is not available.
It can also be used for more sophisticated use cases like a conversion of a audio file to a MIDI sequence (known as Audio-to-MIDI).
For syncing visuals to music in VJing or light show applications (Sound-to-Light) a drum transcription is also an integral part.
Furthermore the drum transcription of a song can be used as a basis for more complicated MIR analysis.
For example using the results of the drum transcription a Beats per Minute (BPM) detection can be build, which in turn can then be the basis of a tempo detection algorithm.
Overall the drum transcription of a song is a basic but versatile information, that can be used in many different applications.


On first sight extracting the time point of a drum hit for a polyphonic, mixed piece of music sounds like a difficult task.
In fact though there are multiple mathematically simple algorithm to achieve that.
For this research we took an algorithm commonly used for these kind of problems: the non-negative matrix factorization (NMF).
Section \ref{sec:algo} will show a detailed explanation of how the NMF works.


%\noindent\makebox[\linewidth]{\rule{\linewidth}{0.4pt}}
%context, problem, use cases
%definitions
%paper overview

%Kurzes Umreißen des Themengebiets mit schneller Fokussierung auf den zu untersuchenden Gegenstand.
%Hierzu können technikhistorische Aspekte oder eine Forschungstradition skizziert, ein
%bestehender theoretischer Hintergrund erhellt, eine Einordnung in Forschungsdisziplinen vorgenommen
%und ggf. ein persönliches Forschungsinteresse dargelegt werden. Die Einführung des
%Themengebiets sollte auf eine konkrete Fragestellung zugespitzt werden, gleichzeitig soll die Relevanz
%des Themas deutlich werden, z.B. mit Hinblick auf Gesellschaft, Grundlagenforschung oder
%konkrete Anwendungen. 

% section intro (end)


\section{Related work}
\label{sec:rel}

The idea to use NMF for pattern recognition was first proposed by Lee and Seung in 1999 \cite{lee1999}.
As described in their paper NMF is a versatile technique to find features in a data set.
Lee and Seung proposed in their paper that it can be used to recognize parts in faces, find semantic features in texts or find certain musical events in a piece of music.
During the last decade NMF was researched and applied in all the fields they mentioned and many more.

In the field of MIR NMF has also been used in a variety of applications.
Most notable are the fields of source separation and music transcription.
For source separation the goal is to separate a piece of music containing a mix of multiple sound sources into the their components.
%T. Virtanen \cite{virtanen2007} among many others has researched this topic.
\cite{virtanen2007}

In the field of music transcription NMF has also been used for different topics.
Smaragdis and Brown \cite{smaragdis2003} used NMF to analyze and extract polyphonic, harmonic content from a piece of music.
In the sub-field of drum transcription there has also been some research in the recent years.
Paulus and Virtanen \cite{paulus2005} as well as Moreau and Flexer \cite{moreau2007} as well as Wu and Lerch \cite{wu2015} have all shown that NMF is a technique that can be well applied to the problem of finding the time points of percussive events in music.



%\noindent\makebox[\linewidth]{\rule{\linewidth}{0.4pt}}
%literature review, state of the art

%Überblick über bestehende Arbeiten im thematisch näheren Forschungsbereich. Der Autor vermittelt
%hier zum einen seine Kenntnis der Materie und zeigt zum anderen Forschungsdefizite und ggf.
%Anknüpfungspunkte an bestehende Arbeiten auf. Daraus ergeben sich die Forschungsrelevanz,
%eine weitere thematische Eingrenzung sowie mögliche methodische Ansätze.

% section rel (end)


\section{Algorithm overview and description}
\label{sec:algo}

As mentioned above we use a \textbf{non-negative matrix factorization} to extract the time points of drum events from a drum track.
In general terms the NMF factorizes a matrix (usually called $\mathbf{V}$) into two smaller matrices (usually called $\mathbf{W}$ and $\mathbf{H}$) with the constraint that every matrix element must be non-negative.
In turn the sum of $\mathbf{W}$ and $\mathbf{H}$ is an approximation of $\mathbf{V}$ (see figure \ref{fig:NMF}).

\begin{figure}[htb]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{figures/NMF}}
%  \vspace{2.0cm}
  \medskip
\end{minipage}

\caption{Matrix $\mathbf{V}$ can be factorized into two matrices $\mathbf{W}$ and $\mathbf{H}$, so that their sum approximates $\mathbf{V}$. \scriptsize{\textsf{\textcopyright} WikiMedia CC BY-SA 3.0}}
\label{fig:NMF}

\end{figure}

In our case we use the magnitude spectrum of a song as the $\mathbf{V}$ matrix and decomposed it into two matrices.
The first one contains the magnitude spectra of the individual components we are interested in ($\mathbf{W}$) and the second one contains the time-varying gain of these components ($\mathbf{H}$), which tells us when each of the components for the first matrix is active.
For that reason the $\mathbf{W}$ matrix is usually called component matrix and $\mathbf{H}$ is usually called activation matrix.
Again the sum of both of these matrices makes up an approximation of the original spectrum \cite{smaragdis2003}.
A visual representation of that can be seen in figure \ref{fig:MatrixOverview} (d).

For our use case we were not interested in finding all the components and their activations.
We were rather interested in finding the corresponding activation of a specific component, like that of a base drum or a hi-hat.
This is also possible using NMF.
In order to do so, we specified $\mathbf{W}$ as the spectrum of a base drum (see figure \ref{fig:MatrixOverview} (b)) and $\mathbf{V}$ continued to be the spectrum of the whole song (see figure \ref{fig:MatrixOverview} (a)).
The NMF then solves for the matrix $\mathbf{H}$ (see figure \ref{fig:MatrixOverview} (c)) which tells us at what point in time the specified base drum spectrum appears in the song.
In that setup the NMF essentially works as a pattern matching algorithm.

\begin{figure}[htb]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{figures/MatrixOverview}}
%  \vspace{2.0cm}
  \medskip
\end{minipage}

\caption{(a) Magnitude spectrum of a drum track. (b) Magnitude spectrum of a base drum. (c) Activation matrix of the base drum. (d) Approximated spectrum. \scriptsize{\textsf{\textcopyright} Own work CC BY-SA 3.0}}
\label{fig:MatrixOverview}

\end{figure}


\begin{figure}[htb]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{figures/Flowchart}}
%  \vspace{2.0cm}
  \medskip
\end{minipage}

\caption{Flowchart of the whole drum transcription algorithm. \scriptsize{\textsf{\textcopyright} Own work CC BY-SA 3.0}}
\label{fig:Flowchart}

\end{figure}


Figure \ref{fig:Flowchart} shows a flowchart with the complete overview of the algorithm we developed.
On the left hand side the two inputs to the algorithms are shown.
The first input is a time domain signal of percussive instrument, like a base drum or hi-hat, and the second input is a time domain signal of a piece of music.
For both inputs the first step is to down mix the signals into a mono signal.
Next the short-time Fourier transform (STFT) is applied, which transforms both signal from the time domain to the frequency domain.
For the parameters of the STFT we used a frame size of 1024 samples which yields in a frequency resolution of approx. 43 Hz per bin.
We also chose an overlap of 50\% between hops to improve the time resolution.
As mentioned before a visual representations of both transformed inputs can be found in figure \ref{fig:MatrixOverview} (b) and (a) respectively.

Before both inputs are fed into the actual detection the drum sound undergoes some further processing.
This step is marked as \textbf{template extraction} in figure \ref{fig:Flowchart}.
For our base drum template we chose to only use the transient of the base drum.
This has the advantage that it makes the template independent of the length of the original base drum sound.
As most of the energy is in the transient it is the most relevant part of the base drum sound.
Using only the transient also makes the template somewhat independent of the room it was recorded in, as any possible reverberation or echo is cut off.


After both inputs are prepared they are handed over to the NMF, which does its processing in the way described before.
The result of the NMF is in our case the activation matrix $\mathbf{H}$.
The matrix $\mathbf{H}$ can also be viewed as a function curve of how much the given template is contributing to the given music signal over time.
The next step of the algorithm is called \textbf{onset detection} where we extract the exact time points from the matrix $\mathbf{H}$.
An alternative representation of the matrix $\mathbf{H}$ as a curve can be seen in figure \ref{fig:ActivationMatrix}.
\begin{figure}[htb]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{figures/ActivationMatrix}}
%  \vspace{2.0cm}
  \medskip
\end{minipage}

\caption{Example of the representation of an activation matrix as a curve. With a red line marking the threshold at $\frac{2}{3}$. \scriptsize{\textsf{\textcopyright} Own work CC BY-SA 3.0}}
\label{fig:ActivationMatrix}

\end{figure}
The onset detection is a simple implementation loosely based on the algorithms described by Lerch \cite{lerch2012book} in chapter 6.3.
To extract the onsets of the drum events the significant local maxima of the curve (peaks) have to be detected.
In order to do that the curve is first normalized.
Afterwards a threshold of $\frac{2}{3}$ is applied, which can be seen as a red line in figure \ref{fig:ActivationMatrix}.
This value was establish empirically to separate the valid detections from false positives.
Then the first derivative, which represents the slope of the curve, is calculated, by subtracting each element from the previous one.
An example of the resulting curve can be found in figure \ref{fig:Ableitung}.
In order to find the extract time points of a peak the zero crossings of the resulting curve have to be detected.
Once the frame number of a zero crossing is found, the frame number has to be converted back to a time point.
This is achieved by applying the following formula, where $f_s$ is the sample rate.

\begin{align*}
\label{eq:timePoint}
timePoint = zeroCrossingFrameNumber * \frac{hopSize}{f_s}
\end{align*}

Due to this formula we are only able to get the time point within a range of approx. 12 ms (called epsilon).
Once this calculation is done we receive a list of time points where the given template is found in the song which is the drum transcription we were looking for.

\begin{figure}[htb]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{figures/Ableitung}}
%  \vspace{2.0cm}
  \medskip
\end{minipage}

\caption{An example of the first derivative of the activation function. \scriptsize{\textsf{\textcopyright} Own work CC BY-SA 3.0}}
\label{fig:Ableitung}

\end{figure}


The implementation of our algorithm was done in Python using the numpy/scipy library stack. 
As well as the library nimfa\footnote{NMF library: \url{http://nimfa.biolab.si/}} for NMF calculations.
The entire code repository is licensed under the GPL 3.0 and can be found on GitHub\footnote{Repository: \url{https://github.com/Bendrien/AudioContentAnalysis}}.

%basic NMF description, our peak picking algorithm, maybe libs used

% section algo (end)


\section{Evaluation}
\label{sec:evaluation}

As our test data set we used the ENST-drums database of the Institut Télécom Paris Tech\footnote{ENST drum test database: \url{https://perso.telecom-paristech.fr/~grichard/ENST-drums/}}.
The data set contains recordings of 207 drum tracks split over 3 different drum kits.
In the data set each instrument of the drum kit is recorded separately.
For our purposes we use the mixed version of the tracks called ``wet-mix'' which also contains some acoustic elements of the recording room, like reverberation, making it more realistic for real world applications.
Next to the recordings the test data set also contains an annotation file for each drum track, which lists the occurrence of an instrument as well as the time point it occurred.
This data was used as the ground truth to compare our algorithm against.

In order to evaluate the accuracy of our algorithm we compared the drum events that our algorithm detected with the annotations of the ENST test set.
When comparing the results we took into account the epsilon error margin of approx. 12 ms.
This leaves us with a detection rate for each track.
To get an overall estimate of the accuracy of our algorithm we calculated the median for each drum kit as well as the mean and the standard deviation.
Besides the true positives we also counted the false positives for each track, where our algorithm would detect a drum event, but according to the annotations there is none there.
We calculated the median, mean and standard deviation across all tracks for the false positives as well.
The results of our evaluation for the base drum template can be found in table \ref{tab:results}.


\begin{table}[h]
  \centering
  \begin{tabular}{l | c c c}
      Drum kit  &  1 & 2 & 3 \\
      \# Files &   63 &   75 & 69 \\
      \hline
      Median$_{P}$   & 0.25 & 0.93 & 0.86 \\
      Mean$_{P}$     & 0.27 & 0.89 & 0.80 \\
      $\sigma_P$     & 0.22 & 0.12 & 0.18 \\
      \hline
      Median$_{FP}$   & 0.13 & 0.0 & 0.0 \\
      Mean$_{FP}$     & 0.23 & 0.0 & 0.001 \\
      $\sigma_{FP}$   & 0.29 & 0.0 & 0.001 \\
  \end{tabular}
  \caption{Results of the base drum detection. $_P$ represents the true positives and $_{FP}$ the false positives.}
  \label{tab:results}
\end{table}


As visible in table \ref{tab:results} the results for drum kit 2 are the best with a average of around 90\% accuracy and a fairly low standard deviation.
The same is true for drum kit 3 which had a detection rate in the mid 80's.
Both had none or close to no false positives.
Drum kit 1 shows different accuracy results.
Here only around 25\% of the base drum hits are detected correctly, while the false positive detection is also at around 20\%.
The standard deviation is also significantly higher.

From these results we can see that our algorithm returns very satisfying results for 2 out 3 drum kits from our test data set.
We also found an explanation for the outlier.
When listening to the base drum sounds of the individual drum kits it becomes obvious that drum kit 2 and 3 sound very alike with a sharp, crisp base drum sound, while the drum kit 1 sounds more smooth and mellow.
Since the base drum template used here was extracted from the drum kit 2 it is not very surprising that the algorithm can't find it in the much different sounding drum kit 1.
The solution to this problem would be to use a more generalized base drum template.
This shows an apparent flaw in the design of the algorithm.
It can only work as good as the templates it is provided with.
If the sound the algorithm is looking for is pitched or distorted to much, it won't be picked up.
More on how to improve this work in section \ref{sec:conclusion}.


%ground truth, methodology, metrics
%results
%discussion


% section evaluation (end)


\section{Conclusion}
\label{sec:conclusion}

In conclusions the algorithm returns surprising good results given its relative simplicity.
As with all pattern matching algorithms if the feature the algorithm is looking for differs to much from the provided template the accuracy declines, even if a human listener is still able to pick them out.
Work by Lerch et al. \cite{lerch2015} has shown that by introducing an additional step into the algorithm this problem can be mitigated.
The step is called template adaption and happens between the NMF and the onset detection in figure \ref{fig:Flowchart}.
Through different methods described in their paper it is possible to iteratively adapt the template to the detections in the music.
That way an ``over-fitting'' of the template to a certain drum kit can be avoided.

Another area of improvement is the onset detection with special focus on the peak picking algorithm.
Here the empirically chosen threshold value of $\frac{2}{3}$ already yield good results, but it is also responsible for some missed events and some false positives.
Using an adaptive threshold would further improve the outcome.

As mentioned above the precision of the detected peak time point is only precise within an epsilon range of approx. 12 ms since only the STFT frame it occurring in can be tracked.
By interpolating between nearby frames the accuracy of the point of inflection could be improved making the epsilon range significant smaller.

Originally we wanted to test our drum transcription algorithm on a piece of mixed polyphonic music instead of just drum tracks.
Sadly we were unable to find an annotated test data set that fit our needs as a ground truth.
Theoretically by using mixed music only the activation matrix $\mathbf{H}$ should get a bit more noisy.
Everything else should work as described here.

In closing we have presented an algorithm in this paper that gives satisfying results when trying to exact the exact time points at which base drum hits happen in a drum track.
It can easily be extended to other percussive instruments and maybe even other melodic instruments.
The accuracy and precision could be improved in future work by the methods mentioned.

%summary, noteworthy parts of the presented work,
%achievements and contributions
%possible improvements and future work

% section conclusion (end)

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

%\end{document}


% DELETE EVERYTHING FROM HERE IN THE END
% DELETE EVERYTHING FROM HERE IN THE END
% DELETE EVERYTHING FROM HERE IN THE END

\vfill\pagebreak

\section{common flaws}
all cited papers should appear in bibliography
vice versa: all references should be mentioned in the paper
each reference should contain:
names of authors
title of the paper or book
conference paper: name of conf. incl. year and location
journal paper: name of journal incl. volume, year and pages
book: publisher, potentially editor
all figures and tables must be referenced in the paper
equations:
all mathematical symbols must be explained
symbols should be used consistently and unambiguously
abbreviations (STFT, DFT, etc.) should be introduced
”The short-time Fourier transform (STFT) is given by (. . .)
We compute the STFT of the signal, (. . .)”

\section{Evaluation}

form (structure, language, form of references)
content (introduction, literature review, algorithm and
evaluation description, figures, comprehensibility, correctness)
evaluation (dataset, metrics, discussion)

\end{document}
